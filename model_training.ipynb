{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53rQmq7GfRKl"
      },
      "source": [
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Numpy\n",
        "import numpy as np\n",
        "# Pillow\n",
        "from PIL import Image\n",
        "# Torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs6gHlPJfbNt"
      },
      "source": [
        "from dataloaders import *\n",
        "from model_classes import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0go4bgYEUSk"
      },
      "source": [
        "ld_val = Lung_Val_Dataset1()\n",
        "ld_test = Lung_Test_Dataset1()\n",
        "ld_train = Lung_Train_Dataset1()\n",
        "\n",
        "ld_val2 = Lung_Val_Dataset2()\n",
        "ld_test2 = Lung_Test_Dataset2()\n",
        "ld_train2 = Lung_Train_Dataset2()\n",
        "\n",
        "ld_val3 = Lung_Val_Dataset3()\n",
        "ld_test3 = Lung_Test_Dataset3()\n",
        "ld_train3 = Lung_Train_Dataset3()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJQR2nA9EXYj"
      },
      "source": [
        "bs_val = 32 #batch size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsT5-3ZXEZwx"
      },
      "source": [
        "# Dataloader from dataset\n",
        "train_loader = DataLoader(ld_train, batch_size = bs_val, shuffle = True)\n",
        "test_loader = DataLoader(ld_test, batch_size = bs_val, shuffle = True)\n",
        "val_loader = DataLoader(ld_val, batch_size = bs_val, shuffle = True)\n",
        "\n",
        "# Dataloader from dataset2\n",
        "train_loader2 = DataLoader(ld_train2, batch_size = bs_val, shuffle = True)\n",
        "test_loader2 = DataLoader(ld_test2, batch_size = bs_val, shuffle = True)\n",
        "val_loader2 = DataLoader(ld_val2, batch_size = bs_val, shuffle = True)\n",
        "\n",
        "# Dataloader from dataset3\n",
        "train_loader3 = DataLoader(ld_train3, batch_size = bs_val, shuffle = True)\n",
        "test_loader3 = DataLoader(ld_test3, batch_size = bs_val, shuffle = True)\n",
        "val_loader3 = DataLoader(ld_val3, batch_size = bs_val, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qp2Q6jTFIMY"
      },
      "source": [
        "#hyper parameters:\n",
        "n_epochs = 10\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QmJidE5E8TY"
      },
      "source": [
        "# Create model\n",
        "model = Net2()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2QYK1N8Ea5C"
      },
      "source": [
        "# Define validation function \n",
        "def validation(model, testloader, criterion):\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for images, labels in testloader:\n",
        "        output = model.forward(images)\n",
        "        test_loss += criterion(output, torch.max(labels, 1)[1]).item()\n",
        "        \n",
        "        ps = torch.exp(output)\n",
        "        equality = (torch.max(labels, 1)[1].data == ps.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "\n",
        "    return test_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK4N3DaSFxur"
      },
      "source": [
        "# set model name\n",
        "model_name = \"model_new\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojdq_IclGG66"
      },
      "source": [
        "running_loss = 0\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "accuracies = []\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader3):\n",
        "        #print(batch_idx)\n",
        "        #images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model.forward(images)\n",
        "        #loss = criterion(output, labels)\n",
        "        loss = criterion(output, torch.max(labels, 1)[1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Eval mode for predictions\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off gradients for validation\n",
        "    with torch.no_grad():\n",
        "        test_loss, accuracy = validation(model, test_loader3, criterion, 1)\n",
        "\n",
        "    accur = accuracy.item()/len(test_loader3)\n",
        "    train_loss = running_loss/bs_val\n",
        "    val_loss = test_loss/len(test_loader3)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    accuracies.append(accur)\n",
        "\n",
        "    print(\"Training Loss is \" + str(train_loss) + \" | Test Loss is: \" + str(val_loss) + \" | Accuracy is: \" + str(accur))\n",
        "    print(\"\\n\")\n",
        "    train_losses.append(running_loss/bs_val)\n",
        "    val_losses.append(test_loss/len(test_loader3))\n",
        "    running_loss = 0\n",
        "\n",
        "    # Make sure training is back on\n",
        "    model.train()\n",
        "\n",
        "    #save the current epoch model.\n",
        "    torch.save({\n",
        "            'epoch': n_epochs,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \"models/\" + model_name + \"_epoch\" + str(e+1) + \".pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsRuWQ4lLZr0"
      },
      "source": [
        "#save the train loss, test loss and accuracy as a csv file\n",
        "df = pd.DataFrame()\n",
        "df[\"train_loss\"] = train_losses\n",
        "df[\"test_loss\"] = val_losses\n",
        "df[\"accuracy\"] = accuracies\n",
        "\n",
        "df.to_excel(\"training_logs/\" + model_name + \".xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C13vlGMTPLK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}